{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,cv2,gc\n",
    "\n",
    "import soundfile\n",
    "import librosa\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from radam import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/train_short_audio'\n",
    "LABELS = 'data/train_metadata.csv'\n",
    "PATH_VAL = 'data/train_soundscapes/'\n",
    "LABELS_VAL = 'data/train_soundscape_labels.csv'\n",
    "NOISE = 'data/rainforest/test_c/'\n",
    "NUM_WORKERS = 12\n",
    "nfolds = 4\n",
    "SEED = 2020\n",
    "OUT = 'shift'\n",
    "bs = 156\n",
    "\n",
    "class config:\n",
    "    sampling_rate = 32000\n",
    "    duration = 5.0075\n",
    "    sz = int(16*duration/5.007+0.5)\n",
    "    samples = int(sampling_rate*duration)\n",
    "    samples_val = int(sampling_rate*5.0075)\n",
    "    top_db = 60\n",
    "    \n",
    "    # Frequencies kept in spectrograms\n",
    "    fmin = 50\n",
    "    fmax =  14000\n",
    "\n",
    "    # Spectrogram parameters\n",
    "    n_mels = 128\n",
    "    n_fft = 2048\n",
    "    hop_length = 313\n",
    "    \n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>filename</th>\n",
       "      <th>license</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "      <th>label</th>\n",
       "      <th>label_s</th>\n",
       "      <th>split</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acafly</td>\n",
       "      <td>['amegfi']</td>\n",
       "      <td>['begging call', 'call', 'juvenile']</td>\n",
       "      <td>35.3860</td>\n",
       "      <td>-84.1250</td>\n",
       "      <td>Empidonax virescens</td>\n",
       "      <td>Acadian Flycatcher</td>\n",
       "      <td>Mike Nelson</td>\n",
       "      <td>2012-08-12</td>\n",
       "      <td>XC109605.ogg</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-ShareAlike 3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>09:30</td>\n",
       "      <td>https://www.xeno-canto.org/109605</td>\n",
       "      <td>0</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0</td>\n",
       "      <td>data/train_short_audio/acafly/XC109605.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acafly</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call']</td>\n",
       "      <td>9.1334</td>\n",
       "      <td>-79.6501</td>\n",
       "      <td>Empidonax virescens</td>\n",
       "      <td>Acadian Flycatcher</td>\n",
       "      <td>Allen T. Chartier</td>\n",
       "      <td>2000-12-26</td>\n",
       "      <td>XC11209.ogg</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-ShareAlike 3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>?</td>\n",
       "      <td>https://www.xeno-canto.org/11209</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>data/train_short_audio/acafly/XC11209.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acafly</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call']</td>\n",
       "      <td>5.7813</td>\n",
       "      <td>-75.7452</td>\n",
       "      <td>Empidonax virescens</td>\n",
       "      <td>Acadian Flycatcher</td>\n",
       "      <td>Sergio Chaparro-Herrera</td>\n",
       "      <td>2012-01-10</td>\n",
       "      <td>XC127032.ogg</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-ShareAlike 3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15:20</td>\n",
       "      <td>https://www.xeno-canto.org/127032</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>data/train_short_audio/acafly/XC127032.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acafly</td>\n",
       "      <td>['whwbec1']</td>\n",
       "      <td>['call']</td>\n",
       "      <td>4.6717</td>\n",
       "      <td>-75.6283</td>\n",
       "      <td>Empidonax virescens</td>\n",
       "      <td>Acadian Flycatcher</td>\n",
       "      <td>Oscar Humberto Marin-Gomez</td>\n",
       "      <td>2009-06-19</td>\n",
       "      <td>XC129974.ogg</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-ShareAlike 3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>07:50</td>\n",
       "      <td>https://www.xeno-canto.org/129974</td>\n",
       "      <td>0</td>\n",
       "      <td>[370]</td>\n",
       "      <td>3</td>\n",
       "      <td>data/train_short_audio/acafly/XC129974.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acafly</td>\n",
       "      <td>['whwbec1']</td>\n",
       "      <td>['call']</td>\n",
       "      <td>4.6717</td>\n",
       "      <td>-75.6283</td>\n",
       "      <td>Empidonax virescens</td>\n",
       "      <td>Acadian Flycatcher</td>\n",
       "      <td>Oscar Humberto Marin-Gomez</td>\n",
       "      <td>2009-06-19</td>\n",
       "      <td>XC129981.ogg</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-ShareAlike 3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>07:50</td>\n",
       "      <td>https://www.xeno-canto.org/129981</td>\n",
       "      <td>0</td>\n",
       "      <td>[370]</td>\n",
       "      <td>0</td>\n",
       "      <td>data/train_short_audio/acafly/XC129981.ogg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  primary_label secondary_labels                                  type  \\\n",
       "0        acafly       ['amegfi']  ['begging call', 'call', 'juvenile']   \n",
       "1        acafly               []                              ['call']   \n",
       "2        acafly               []                              ['call']   \n",
       "3        acafly      ['whwbec1']                              ['call']   \n",
       "4        acafly      ['whwbec1']                              ['call']   \n",
       "\n",
       "   latitude  longitude      scientific_name         common_name  \\\n",
       "0   35.3860   -84.1250  Empidonax virescens  Acadian Flycatcher   \n",
       "1    9.1334   -79.6501  Empidonax virescens  Acadian Flycatcher   \n",
       "2    5.7813   -75.7452  Empidonax virescens  Acadian Flycatcher   \n",
       "3    4.6717   -75.6283  Empidonax virescens  Acadian Flycatcher   \n",
       "4    4.6717   -75.6283  Empidonax virescens  Acadian Flycatcher   \n",
       "\n",
       "                       author        date      filename  \\\n",
       "0                 Mike Nelson  2012-08-12  XC109605.ogg   \n",
       "1           Allen T. Chartier  2000-12-26   XC11209.ogg   \n",
       "2     Sergio Chaparro-Herrera  2012-01-10  XC127032.ogg   \n",
       "3  Oscar Humberto Marin-Gomez  2009-06-19  XC129974.ogg   \n",
       "4  Oscar Humberto Marin-Gomez  2009-06-19  XC129981.ogg   \n",
       "\n",
       "                                                     license  rating   time  \\\n",
       "0  Creative Commons Attribution-NonCommercial-ShareAlike 3.0     2.5  09:30   \n",
       "1  Creative Commons Attribution-NonCommercial-ShareAlike 3.0     3.0      ?   \n",
       "2  Creative Commons Attribution-NonCommercial-ShareAlike 3.0     3.0  15:20   \n",
       "3  Creative Commons Attribution-NonCommercial-ShareAlike 3.0     3.5  07:50   \n",
       "4  Creative Commons Attribution-NonCommercial-ShareAlike 3.0     3.5  07:50   \n",
       "\n",
       "                                 url  label label_s  split  \\\n",
       "0  https://www.xeno-canto.org/109605      0     [5]      0   \n",
       "1   https://www.xeno-canto.org/11209      0      []      2   \n",
       "2  https://www.xeno-canto.org/127032      0      []      3   \n",
       "3  https://www.xeno-canto.org/129974      0   [370]      3   \n",
       "4  https://www.xeno-canto.org/129981      0   [370]      0   \n",
       "\n",
       "                                        fname  \n",
       "0  data/train_short_audio/acafly/XC109605.ogg  \n",
       "1   data/train_short_audio/acafly/XC11209.ogg  \n",
       "2  data/train_short_audio/acafly/XC127032.ogg  \n",
       "3  data/train_short_audio/acafly/XC129974.ogg  \n",
       "4  data/train_short_audio/acafly/XC129981.ogg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(LABELS)\n",
    "label_map = {p:i for i,p in enumerate(sorted(df.primary_label.unique()))}\n",
    "df['label'] = df.primary_label.map(label_map)\n",
    "df['label_s'] = [[label_map[e.split('_')[-1]] for e in l.split('\\'')[1::2] if e.split('_')[-1] in label_map] \\\n",
    "       for l in df.secondary_labels] \n",
    "\n",
    "splits = StratifiedKFold(n_splits=nfolds, random_state=SEED, shuffle=True)\n",
    "df['split'] = 0\n",
    "for i,s in enumerate(list(splits.split(df,df.label))): df.loc[s[1],'split'] = i\n",
    "df['fname'] = [os.path.join(PATH,l,f) for f,l in zip(df.filename,df.primary_label)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_split = [['7954_COR_20190923.ogg','11254_COR_20190904.ogg','54955_SSW_20170617.ogg',\n",
    " '51010_SSW_20170513.ogg','18003_COR_20190904.ogg'],\n",
    "['7019_COR_20190904.ogg','14473_SSW_20170701.ogg','57610_COR_20190904.ogg',\n",
    "'44957_COR_20190923.ogg','21767_COR_20190904.ogg'],\n",
    "['31928_COR_20191004.ogg','50878_COR_20191004.ogg','42907_SSW_20170708.ogg',\n",
    " '26709_SSW_20170701.ogg','28933_SSW_20170408.ogg'],\n",
    "['20152_SSW_20170805.ogg','7843_SSW_20170325.ogg','26746_COR_20191004.ogg',\n",
    " '10534_SSW_20170429.ogg','2782_SSW_20170701.ogg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sqrt, newaxis\n",
    "from numpy.fft import irfft, rfftfreq\n",
    "from numpy.random import normal\n",
    "from numpy import sum as npsum\n",
    "\n",
    "\n",
    "def powerlaw_psd_gaussian(exponent, size, fmin=0):\n",
    "    \"\"\"Gaussian (1/f)**beta noise.\n",
    "    Based on the algorithm in:\n",
    "    Timmer, J. and Koenig, M.:\n",
    "    On generating power law noise.\n",
    "    Astron. Astrophys. 300, 707-710 (1995)\n",
    "    Normalised to unit variance\n",
    "    Parameters:\n",
    "    -----------\n",
    "    exponent : float\n",
    "        The power-spectrum of the generated noise is proportional to\n",
    "        S(f) = (1 / f)**beta\n",
    "        flicker / pink noise:   exponent beta = 1\n",
    "        brown noise:            exponent beta = 2\n",
    "        Furthermore, the autocorrelation decays proportional to lag**-gamma\n",
    "        with gamma = 1 - beta for 0 < beta < 1.\n",
    "        There may be finite-size issues for beta close to one.\n",
    "    shape : int or iterable\n",
    "        The output has the given shape, and the desired power spectrum in\n",
    "        the last coordinate. That is, the last dimension is taken as time,\n",
    "        and all other components are independent.\n",
    "    fmin : float, optional\n",
    "        Low-frequency cutoff.\n",
    "        Default: 0 corresponds to original paper. It is not actually\n",
    "        zero, but 1/samples.\n",
    "    Returns\n",
    "    -------\n",
    "    out : array\n",
    "        The samples.\n",
    "    Examples:\n",
    "    ---------\n",
    "    # generate 1/f noise == pink noise == flicker noise\n",
    "    >>> import colorednoise as cn\n",
    "    >>> y = cn.powerlaw_psd_gaussian(1, 5)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make sure size is a list so we can iterate it and assign to it.\n",
    "    try:\n",
    "        size = list(size)\n",
    "    except TypeError:\n",
    "        size = [size]\n",
    "    \n",
    "    # The number of samples in each time series\n",
    "    samples = size[-1]\n",
    "    \n",
    "    # Calculate Frequencies (we asume a sample rate of one)\n",
    "    # Use fft functions for real output (-> hermitian spectrum)\n",
    "    f = rfftfreq(samples)\n",
    "    \n",
    "    # Build scaling factors for all frequencies\n",
    "    s_scale = f\n",
    "    fmin = max(fmin, 1./samples) # Low frequency cutoff\n",
    "    ix   = npsum(s_scale < fmin)   # Index of the cutoff\n",
    "    if ix and ix < len(s_scale):\n",
    "        s_scale[:ix] = s_scale[ix]\n",
    "    s_scale = s_scale**(-exponent/2.)\n",
    "    \n",
    "    # Calculate theoretical output standard deviation from scaling\n",
    "    w      = s_scale[1:].copy()\n",
    "    w[-1] *= (1 + (samples % 2)) / 2. # correct f = +-0.5\n",
    "    sigma = 2 * sqrt(npsum(w**2)) / samples\n",
    "    \n",
    "    # Adjust size to generate one Fourier component per frequency\n",
    "    size[-1] = len(f)\n",
    "\n",
    "    # Add empty dimension(s) to broadcast s_scale along last\n",
    "    # dimension of generated random power + phase (below)\n",
    "    dims_to_add = len(size) - 1\n",
    "    s_scale     = s_scale[(newaxis,) * dims_to_add + (Ellipsis,)]\n",
    "    \n",
    "    # Generate scaled random power + phase\n",
    "    sr = normal(scale=s_scale, size=size)\n",
    "    si = normal(scale=s_scale, size=size)\n",
    "    \n",
    "    # If the signal length is even, frequencies +/- 0.5 are equal\n",
    "    # so the coefficient must be real.\n",
    "    if not (samples % 2): si[...,-1] = 0\n",
    "    \n",
    "    # Regardless of signal length, the DC component must be real\n",
    "    si[...,0] = 0\n",
    "    \n",
    "    # Combine power + corrected phase to Fourier components\n",
    "    s  = sr + 1J * si\n",
    "    \n",
    "    # Transform to real time series & scale to unit variance\n",
    "    y = irfft(s, n=samples, axis=-1) / sigma\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = -40.0,12.0 #quick estimation\n",
    "\n",
    "def img2tensor(img,dtype:np.dtype=np.float32):\n",
    "    if img.ndim==2 : img = np.expand_dims(img,2)\n",
    "    img = np.transpose(img,(2,0,1))\n",
    "    return torch.from_numpy(img.astype(dtype, copy=False))\n",
    "\n",
    "class BirdDatasetS(Dataset):\n",
    "    def __init__(self, df, PL, train=True, tfms=None, noise=True):\n",
    "        self.df = df.copy()\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        self.train = train\n",
    "        self.tfms = tfms\n",
    "        self.noise = None\n",
    "        self.pl = pickle.load(open(PL,'rb')) if PL is not None else None\n",
    "        self.pl_th1 = 0.6#2.3\n",
    "        self.pl_th2 = -1.5#0.0\n",
    "        \n",
    "        self.noise = noise\n",
    "        self.pink = 0.001*powerlaw_psd_gaussian(1,5000*config.sampling_rate)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            label,label_s,fname,fidx = self.df.iloc[idx][['label','label_s','fname','filename']]\n",
    "            f = soundfile.info(fname)\n",
    "            l = f.frames\n",
    "            assert(f.samplerate == config.sampling_rate)\n",
    "            pl = self.pl[fidx]\n",
    "            selection = pl[label] > self.pl_th1\n",
    "            if selection.max(): break\n",
    "            else: idx = np.random.randint(len(self.df))\n",
    "            \n",
    "        ids = torch.where(selection)[0]\n",
    "        pl_start = ids[random.randint(0,len(ids)-1)]\n",
    "        pl_start = max(0,pl_start-random.randint(0,config.sz-2))\n",
    "        pl_end = pl_start + config.sz\n",
    "        if pl_end > pl.shape[1]: \n",
    "            pl_end = pl.shape[1]\n",
    "            pl_start = max(0,pl_end - config.sz)\n",
    "        pl = pl[:,pl_start:pl_end]\n",
    "        if config.sz - pl_end+pl_start != 0: pl = F.pad(pl,[0,config.sz-pl_end+pl_start,0,0])\n",
    "        \n",
    "        effective_length = config.samples\n",
    "        start = max(0,min(int((pl_start)*32*config.hop_length + random.randint(0,config.n_fft) +\n",
    "                          random.randint(-4*config.hop_length,4*config.hop_length)),\n",
    "                          l - effective_length))\n",
    "        if l <= effective_length: wave, sr = soundfile.read(fname)\n",
    "        else: wave, sr = soundfile.read(fname,start=start,stop=start+effective_length)\n",
    "        if effective_length > len(wave): wave = np.pad(wave,(0,effective_length - len(wave)))\n",
    "        wave= wave.astype(np.float32)\n",
    "        if self.train:\n",
    "            shape = wave.shape[0]\n",
    "            s_idx = np.random.randint(self.pink.shape[0] - shape)\n",
    "            noise = self.pink[s_idx:s_idx+shape]\n",
    "            if self.noise and random.random() > 0.25:\n",
    "                while True:\n",
    "                    fname = os.path.join(NOISE,random.choice(os.listdir(NOISE)))\n",
    "                    f = soundfile.info(fname).frames\n",
    "                    if f > effective_length: break\n",
    "                e = random.randint(effective_length,f-1)\n",
    "                n, sr = soundfile.read(fname,start=e-effective_length,stop=e)\n",
    "                noise += n\n",
    "            wave = min(1.0,max(0.15,np.random.exponential(0.4)))*wave+noise\n",
    "\n",
    "        mel = librosa.feature.melspectrogram(wave, \n",
    "                    sr=config.sampling_rate,\n",
    "                    n_mels=config.n_mels,\n",
    "                    hop_length=config.hop_length,\n",
    "                    n_fft=config.n_fft,\n",
    "                    fmin=config.fmin,\n",
    "                    fmax=config.fmax)\n",
    "        logmel = librosa.power_to_db(mel).astype(np.float32)\n",
    "        label = F.one_hot(torch.LongTensor([label]), len(label_map)).float().squeeze()\n",
    "        if len(label_s) > 0: label += 0.5*F.one_hot(torch.LongTensor(label_s), len(label_map)).float().sum(0)\n",
    "        maskp = pl > self.pl_th1\n",
    "        maskn = pl > self.pl_th2\n",
    "        maskn[~((label > 0) | maskp.max(-1)[0]).unsqueeze(-1).repeat(1,config.sz)] = False\n",
    "        return {'spec':(img2tensor(logmel) - mean)/std}, \\\n",
    "            {'label':label*0.999 + 0.001, 'pl_maskp': maskp if pl is not None else None, \\\n",
    "             'pl_maskn':maskn if pl is not None else None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDatasetVal(Dataset):\n",
    "    def __init__(self,fold=-1):\n",
    "        df = pd.read_csv(LABELS_VAL)\n",
    "        df['file'] = ['_'.join(row.row_id.split('_')[:-1]) for idx,row in df.iterrows()]\n",
    "        df['birds'] = [[label_map[b] for b in row.birds.split(' ') if b in label_map] for idx,row in df.iterrows()]\n",
    "        file_map = {'_'.join(f.split('_')[:-1]):f for f in os.listdir(PATH_VAL)}\n",
    "        df['file'] = df.file.map(file_map)\n",
    "        if fold < len(noise_split) and fold >= 0: self.df = df[df.file.isin(noise_split[fold])]\n",
    "        elif fold == 4: self.df = df.loc[df.seconds <= 300].reset_index(drop=True)\n",
    "        elif fold == 5: self.df = df.loc[df.seconds > 300].reset_index(drop=True)\n",
    "        else: self.df = df.reset_index(drop=True)\n",
    "        self.data = {fname:soundfile.read(os.path.join(PATH_VAL,fname))[0] for fname in list(df.file.unique())}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label,fname,end = self.df.iloc[idx][['birds','file','seconds']]\n",
    "        end *= config.sampling_rate\n",
    "        length = config.samples_val\n",
    "        start = max(0, end - length)\n",
    "        wave = self.data[fname][start:start+length]\n",
    "        \n",
    "        mel = librosa.feature.melspectrogram(wave, \n",
    "                    sr=config.sampling_rate,\n",
    "                    n_mels=config.n_mels,\n",
    "                    hop_length=config.hop_length,\n",
    "                    n_fft=config.n_fft,\n",
    "                    fmin=config.fmin,\n",
    "                    fmax=config.fmax)\n",
    "        logmel = librosa.power_to_db(mel).astype(np.float32)\n",
    "        label = F.one_hot(torch.LongTensor(label), len(label_map)).float().sum(0) if len(label) > 0 \\\n",
    "          else torch.zeros(len(label_map))\n",
    "        return {'spec':(img2tensor(logmel) - mean)/std}, {'label':label*0.999 + 0.001}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-09T19:29:03.013286Z",
     "iopub.status.busy": "2020-09-09T19:29:03.011395Z",
     "iopub.status.idle": "2020-09-09T19:29:03.013993Z",
     "shell.execute_reply": "2020-09-09T19:29:03.014397Z"
    },
    "papermill": {
     "duration": 0.028201,
     "end_time": "2020-09-09T19:29:03.014511",
     "exception": false,
     "start_time": "2020-09-09T19:29:02.986310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, n=512, nheads=8, dim_feedforward=512):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(n,nheads)\n",
    "        self.norm = nn.LayerNorm(n)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "        x = x.view(shape[0],shape[1],-1).permute(2,0,1)\n",
    "        x = self.norm(self.drop(self.attn(x,x,x)[0]) + x)\n",
    "        x = x.permute(1,2,0).reshape(shape)\n",
    "        return x    \n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n=len(label_map), arch='resnext50_32x4d_ssl', \n",
    "                 path='facebookresearch/semi-supervised-ImageNet1K-models', ps=0.5, \n",
    "                 s_max = 5.0, s_min=-2.0):\n",
    "        super().__init__()\n",
    "        self.s_max,self.s_min = s_max,s_min\n",
    "        m = torch.hub.load(path, arch)\n",
    "        nc = list(m.children())[-1].in_features\n",
    "        self.enc = nn.Sequential(*list(m.children())[:-2])\n",
    "        \n",
    "        shape = self.enc[0].weight.shape\n",
    "        w = self.enc[0].weight.sum(1).unsqueeze(1)\n",
    "        self.enc[0] = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.enc[0].weight = nn.Parameter(w)\n",
    "\n",
    "        nh = 768\n",
    "        self.head = nn.Sequential(nn.Conv2d(nc,nh,(config.n_mels//32,1)),AttnBlock(nh),AttnBlock(nh),\n",
    "                                  nn.Conv2d(nh,n,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.head(self.enc(x['spec']))\n",
    "        #bs,n,1,len//32\n",
    "        x_g = torch.logsumexp(x*self.s_max,-1).squeeze(-1)/self.s_max\n",
    "        x_min = torch.logsumexp(x*self.s_min,-1).squeeze(-1)/self.s_min\n",
    "        return {'pred':x.squeeze(2), 'pred_g':x_g, 'pred_min':x_min}\n",
    "        \n",
    "    split_layers = lambda m: [list(m.module.enc.parameters()), list(m.module.head.parameters())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madgrad import MADGRAD\n",
    "from radam import Over9000\n",
    "\n",
    "def WrapperMADGRAD(param_groups,**kwargs):\n",
    "    return OptimWrapper(param_groups,MADGRAD)\n",
    "\n",
    "def WrapperOver9000(param_groups,**kwargs):\n",
    "    return OptimWrapper(param_groups,Over9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct implementation of focal loss for soft labels\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target, reduction='mean'):\n",
    "        #n = input.shape[-1]\n",
    "        input = input.view(-1).float()\n",
    "        target = target.view(-1).float()\n",
    "        loss = -target*F.logsigmoid(input)*torch.exp(self.gamma*F.logsigmoid(-input)) -\\\n",
    "           (1.0 - target)*F.logsigmoid(-input)*torch.exp(self.gamma*F.logsigmoid(input))\n",
    "        \n",
    "        return loss.mean() if reduction=='mean' else loss\n",
    "    \n",
    "#correct implementation of focal loss for soft labels\n",
    "class CombineLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, mul=1.0):\n",
    "        super().__init__()\n",
    "        self.floss = FocalLoss(gamma)\n",
    "        self.mul = mul\n",
    "        \n",
    "    def forward(self, x, y, reduction='mean'):\n",
    "        if 'pl_maskp' not in y:\n",
    "            return self.mul*self.floss(x['pred_g'],y['label']) + \\\n",
    "              0.3*self.floss(x['pred_min'],torch.zeros_like(y['label']))\n",
    "        yg = torch.max(y['label'],0.85*y['pl_maskp'].max(-1)[0])\n",
    "        loss_g = self.floss(x['pred_g'],yg) + 0.3*self.floss(x['pred_min'],torch.zeros_like(y['label']))\n",
    "        if 'pl_maskp' not in y: return loss_g*self.mul\n",
    "        m = (~y['pl_maskn'] | y['pl_maskp'])\n",
    "        loss_s = self.floss(x['pred'][m],y['pl_maskp'][m])\n",
    "        return self.mul*(0.5*loss_g + 0.5*loss_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_m(x,y):\n",
    "    return (x['pred_g'].argmax(-1) == y['label'].argmax(-1)).float().mean()\n",
    "\n",
    "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True):\n",
    "    \"Computes the f_beta between `preds` and `targets`\"\n",
    "    beta2 = beta ** 2\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred = (y_pred>thresh).float()\n",
    "    y_true = y_true.float()\n",
    "    TP = (y_pred*y_true).sum(dim=1)\n",
    "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
    "    rec = TP/(y_true.sum(dim=1)+eps)\n",
    "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
    "    return res.mean()\n",
    "\n",
    "class FBetaMax(Metric):\n",
    "    def __init__(self, beta=1):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.preds = []\n",
    "        self.targets = []\n",
    "        \n",
    "    def reset(self): \n",
    "        self.preds = []\n",
    "        self.targets = []\n",
    "        \n",
    "    def accumulate(self,learn):\n",
    "        x = learn.pred['pred_g'].cpu() \n",
    "        x = torch.cat([x,-x.max(-1)[0].unsqueeze(-1)],1) #account for nocall\n",
    "        y = learn.y['label'].cpu()\n",
    "        y = torch.cat([y,1 - y.max(-1)[0].unsqueeze(-1)],1)\n",
    "        self.preds.append(learn.pred['pred_g'].cpu())\n",
    "        self.targets.append(learn.y['label'].cpu())\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        p = torch.cat(self.preds,0)\n",
    "        t = torch.cat(self.targets,0)\n",
    "        th1,th2 = p.min(), p.max()\n",
    "        nth = 100\n",
    "        metric = torch.stack([fbeta(p,t,thresh=th1+(th2-th1)*i/(nth-1),\n",
    "                                    beta=self.beta,sigmoid=False) for i in range(nth)]).max()\n",
    "        return metric\n",
    "\n",
    "class F1_row(Metric):\n",
    "    def __init__(self,ths=np.arange(-2.5,2.5,0.05)):\n",
    "        super().__init__()\n",
    "        self.ths = ths\n",
    "        self.f1s = []\n",
    "        \n",
    "    def reset(self): \n",
    "        self.f1s = []\n",
    "        \n",
    "    def accumulate(self,learn):\n",
    "        f1s = []\n",
    "        for th in self.ths:\n",
    "            pred = (learn.pred['pred'].max(-1)[0] > th).cpu()\n",
    "            t = learn.y['label'].long().cpu()\n",
    "            f1 = (2.0*(pred*t).sum(1)+1e-6)/(pred.sum(1) + t.sum(1) + 1e-6)\n",
    "            f1s.append(f1)\n",
    "        self.f1s.append(f1s)\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        f1 = torch.cat([torch.stack(f,1) for f in self.f1s],0).mean(0)\n",
    "        return f1.max()\n",
    "    \n",
    "    \n",
    "class AccMax(Metric):\n",
    "    def __init__(self, beta=1):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.preds = []\n",
    "        self.targets = []\n",
    "        \n",
    "    def reset(self): \n",
    "        self.preds = []\n",
    "        self.targets = []\n",
    "        \n",
    "    def accumulate(self,learn):\n",
    "        self.preds.append(learn.pred['pred_g'].cpu())\n",
    "        self.targets.append(learn.y['label'].cpu())\n",
    "        \n",
    "    def get_metric(self,p,t,th):\n",
    "        return ((p > th).long() == t.long()).min(-1)[0].float().mean()\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        p = torch.cat(self.preds,0)\n",
    "        t = torch.cat(self.targets,0)\n",
    "        th1,th2 = p.min(), p.max()\n",
    "        nth = 100\n",
    "        metric = torch.stack([self.get_metric(p,t,th1+(th2-th1)*i/(nth-1)) for i in range(nth)]).max()\n",
    "        return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixUp_audio(MixHandler):\n",
    "    \"Implementation of https://arxiv.org/abs/1710.09412\"\n",
    "    def __init__(self, alpha=4.0, p=0.6): \n",
    "        super().__init__(alpha)\n",
    "        self.p = p\n",
    "        \n",
    "    def before_batch(self):\n",
    "        if random.random() > self.p: return\n",
    "        lam = self.distrib.sample((self.y['label'].size(0),)).squeeze().to(self.x['spec'].device)\n",
    "        lam = torch.stack([lam, 1-lam], 1)\n",
    "        self.lam = lam.max(1)[0]\n",
    "        shuffle = torch.randperm(self.y['label'].size(0)).to(self.x['spec'].device)\n",
    "        xb1,yb1 = self.x['spec'][shuffle],self.y['label'][shuffle]\n",
    "        \n",
    "        nx_dims = len(self.x['spec'].size())\n",
    "        self.learn.x.update({'spec':torch.lerp(xb1,self.x['spec'],unsqueeze(self.lam, n=nx_dims-1))})\n",
    "        self.learn.y.update({'label':torch.max(yb1,self.y['label'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "@delegates(GradScaler)\n",
    "class MixedPrecision(Callback):\n",
    "    \"Mixed precision training using Pytorch's `autocast` and `GradScaler`\"\n",
    "    order = 10\n",
    "    def __init__(self, **kwargs): self.kwargs,self.autocast = kwargs,autocast()\n",
    "    def before_fit(self): self.learn.scaler,self.scales = GradScaler(**self.kwargs),L()\n",
    "    def before_batch(self): self.autocast.__enter__()\n",
    "    def after_pred(self): self.learn.pred = to_float(self.pred) ###\n",
    "    def after_loss(self): self.autocast.__exit__()\n",
    "    def before_backward(self): self.learn.loss_grad = self.scaler.scale(self.loss_grad)\n",
    "    def before_step(self):\n",
    "        self.skipped=True\n",
    "        self.scaler.step(self)\n",
    "        if self.skipped: raise CancelStepException()\n",
    "        self.scales.append(self.scaler.get_scale())\n",
    "    def after_step(self): self.learn.scaler.update()\n",
    "\n",
    "    @property # pretend to be an optimizer for `GradScaler`\n",
    "    def param_groups(self): return self.opt.param_groups\n",
    "    def step(self, *args, **kwargs): self.skipped=False\n",
    "        \n",
    "import fastai\n",
    "fastai.callback.fp16.MixedPrecision = MixedPrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/iafoss/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_row</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.001313</td>\n",
       "      <td>2.180787</td>\n",
       "      <td>0.637084</td>\n",
       "      <td>06:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='34' class='' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      53.12% [34/64 3:51:56<3:24:38]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_row</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.777207</td>\n",
       "      <td>2.074321</td>\n",
       "      <td>0.637084</td>\n",
       "      <td>06:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.680115</td>\n",
       "      <td>2.022089</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>06:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.477623</td>\n",
       "      <td>1.963413</td>\n",
       "      <td>0.643820</td>\n",
       "      <td>06:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.432943</td>\n",
       "      <td>1.929688</td>\n",
       "      <td>0.641736</td>\n",
       "      <td>06:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.437596</td>\n",
       "      <td>2.080068</td>\n",
       "      <td>0.637084</td>\n",
       "      <td>06:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.422902</td>\n",
       "      <td>1.796150</td>\n",
       "      <td>0.668667</td>\n",
       "      <td>06:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.358955</td>\n",
       "      <td>1.854308</td>\n",
       "      <td>0.651973</td>\n",
       "      <td>06:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.358585</td>\n",
       "      <td>1.944603</td>\n",
       "      <td>0.637917</td>\n",
       "      <td>06:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.286693</td>\n",
       "      <td>1.781100</td>\n",
       "      <td>0.666945</td>\n",
       "      <td>06:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.288941</td>\n",
       "      <td>1.795732</td>\n",
       "      <td>0.639722</td>\n",
       "      <td>06:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.275707</td>\n",
       "      <td>1.900485</td>\n",
       "      <td>0.670861</td>\n",
       "      <td>06:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.232175</td>\n",
       "      <td>1.900214</td>\n",
       "      <td>0.644584</td>\n",
       "      <td>06:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.237721</td>\n",
       "      <td>1.839222</td>\n",
       "      <td>0.674500</td>\n",
       "      <td>06:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.210984</td>\n",
       "      <td>1.826410</td>\n",
       "      <td>0.667917</td>\n",
       "      <td>06:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.123945</td>\n",
       "      <td>1.874138</td>\n",
       "      <td>0.679542</td>\n",
       "      <td>06:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.116692</td>\n",
       "      <td>1.848482</td>\n",
       "      <td>0.696111</td>\n",
       "      <td>06:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.181259</td>\n",
       "      <td>1.884308</td>\n",
       "      <td>0.673070</td>\n",
       "      <td>06:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.185525</td>\n",
       "      <td>1.835967</td>\n",
       "      <td>0.689986</td>\n",
       "      <td>06:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.181797</td>\n",
       "      <td>1.852415</td>\n",
       "      <td>0.688750</td>\n",
       "      <td>06:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.107680</td>\n",
       "      <td>1.875734</td>\n",
       "      <td>0.697014</td>\n",
       "      <td>06:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.055241</td>\n",
       "      <td>1.763682</td>\n",
       "      <td>0.699000</td>\n",
       "      <td>06:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.142707</td>\n",
       "      <td>1.736714</td>\n",
       "      <td>0.712903</td>\n",
       "      <td>06:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.134887</td>\n",
       "      <td>1.757456</td>\n",
       "      <td>0.700695</td>\n",
       "      <td>06:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.066721</td>\n",
       "      <td>1.743762</td>\n",
       "      <td>0.695445</td>\n",
       "      <td>06:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.071023</td>\n",
       "      <td>1.700705</td>\n",
       "      <td>0.707306</td>\n",
       "      <td>06:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.106668</td>\n",
       "      <td>1.695840</td>\n",
       "      <td>0.725014</td>\n",
       "      <td>06:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.080958</td>\n",
       "      <td>1.761425</td>\n",
       "      <td>0.699320</td>\n",
       "      <td>06:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.023575</td>\n",
       "      <td>1.809413</td>\n",
       "      <td>0.689847</td>\n",
       "      <td>06:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.034700</td>\n",
       "      <td>1.746593</td>\n",
       "      <td>0.716625</td>\n",
       "      <td>06:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.023970</td>\n",
       "      <td>1.744755</td>\n",
       "      <td>0.719681</td>\n",
       "      <td>06:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.062304</td>\n",
       "      <td>1.808956</td>\n",
       "      <td>0.693875</td>\n",
       "      <td>06:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.079330</td>\n",
       "      <td>1.648220</td>\n",
       "      <td>0.708097</td>\n",
       "      <td>06:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.103127</td>\n",
       "      <td>1.716650</td>\n",
       "      <td>0.703667</td>\n",
       "      <td>06:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.993945</td>\n",
       "      <td>1.792266</td>\n",
       "      <td>0.724459</td>\n",
       "      <td>06:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='252' class='' max='403' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      62.53% [252/403 04:22<02:37 1.8809]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with f1_row value: 0.6370836496353149.\n",
      "Better model found at epoch 1 with f1_row value: 0.6423614025115967.\n",
      "Better model found at epoch 2 with f1_row value: 0.6438197493553162.\n",
      "Better model found at epoch 5 with f1_row value: 0.6686668992042542.\n",
      "Better model found at epoch 10 with f1_row value: 0.6708613634109497.\n",
      "Better model found at epoch 12 with f1_row value: 0.6745002865791321.\n",
      "Better model found at epoch 14 with f1_row value: 0.6795418858528137.\n",
      "Better model found at epoch 15 with f1_row value: 0.6961113214492798.\n",
      "Better model found at epoch 19 with f1_row value: 0.6970140933990479.\n",
      "Better model found at epoch 20 with f1_row value: 0.6990002393722534.\n",
      "Better model found at epoch 21 with f1_row value: 0.7129029631614685.\n",
      "Better model found at epoch 25 with f1_row value: 0.7250140309333801.\n"
     ]
    }
   ],
   "source": [
    "fname = 'shift13'\n",
    "for fold in range(1):\n",
    "    gc.collect()\n",
    "    ds_t = BirdDatasetS(df, PL=f'data/seg0_pl.pickle',train=True)#,noise_path=NOISE_PATH)\n",
    "    ds_v = BirdDatasetVal()\n",
    "    data = ImageDataLoaders.from_dsets(ds_t,ds_v,bs=bs,num_workers=NUM_WORKERS,pin_memory=True).cuda()\n",
    "    gc.collect()\n",
    "    model = Model().cuda()\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "    learn = Learner(data, model, loss_func=CombineLoss(mul=len(label_map)),\n",
    "                    metrics=[F1_row()],opt_func=partial(WrapperOver9000,eps=1e-4),\n",
    "                    cbs=[GradientClip(),MixUp_audio(p=0.85)],splitter=Model.split_layers).to_fp16()\n",
    "\n",
    "    learn.freeze_to(-1)\n",
    "    learn.fit_one_cycle(1, lr_max=0.25e-2, div=5, pct_start=0.0)\n",
    "    torch.cuda.empty_cache()\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(64, lr_max=(0.5e-3,0.5e-3), pct_start=0.0, div=25, div_final=100,moms=[0.91,0.85,0.91],\n",
    "            cbs=SaveModelCallback(monitor='f1_row',comp=np.greater))\n",
    "    torch.save(learn.model.module.state_dict(),os.path.join(OUT,f'{fname}_{fold}.pth'))\n",
    "    \n",
    "    values = torch.cat([torch.stack(f,1) for f in learn.metrics[0].f1s],0).mean(0)\n",
    "    values_ths = learn.metrics[0].ths\n",
    "    best_val = values.max()\n",
    "    best_th = values_ths[values.argmax()]\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(values_ths, values, color='blue')\n",
    "    plt.vlines(x=best_th, ymin=values.min(), ymax=values.max(), colors='black')\n",
    "    d = values.max() - values.min()\n",
    "    dth = values_ths.max() - values_ths.min()\n",
    "    plt.text(values_ths[-1]-0.2*dth, best_val-0.1*d, f'VAL = {best_val:.4f}', fontsize=12);\n",
    "    plt.text(values_ths[-1]-0.2*dth, best_val-0.2*d, f'TH = {best_th:.3f}', fontsize=12);\n",
    "    plt.show()\n",
    "    \n",
    "    del learn, data, ds_t, ds_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "duration": 6038.390191,
   "end_time": "2020-09-09T21:09:32.477182",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-09T19:28:54.086991",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "3a5185c3e35b46888b4b4e45357c5a9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "4727fd250773425189b04efb50ee999e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4bfde4bebc864b39864b11c6792b6627": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e5386ae28d74efebbc4eb404b7e842f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_829d63cd88ea4969b4a8868fc3e2cf91",
       "max": 100428550,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3a5185c3e35b46888b4b4e45357c5a9c",
       "value": 100428550
      }
     },
     "829d63cd88ea4969b4a8868fc3e2cf91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a0746b92cc65415aa8ce9a2c5e529a28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d1417e0a39d44b14989b5133520a8d71",
       "placeholder": "​",
       "style": "IPY_MODEL_4727fd250773425189b04efb50ee999e",
       "value": " 95.8M/95.8M [00:35&lt;00:00, 2.80MB/s]"
      }
     },
     "c6a9c2dc704c4793a020327cc2c30f38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4e5386ae28d74efebbc4eb404b7e842f",
        "IPY_MODEL_a0746b92cc65415aa8ce9a2c5e529a28"
       ],
       "layout": "IPY_MODEL_4bfde4bebc864b39864b11c6792b6627"
      }
     },
     "d1417e0a39d44b14989b5133520a8d71": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
